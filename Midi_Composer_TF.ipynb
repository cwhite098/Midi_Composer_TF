{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "2nd attempt at generating nice music using a neural network. I will be basing this on the following tutorial:\n",
    "https://www.datacamp.com/community/tutorials/using-tensorflow-to-compose-music"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# First I need to create dataset, this will be done via webscraping\n",
    "\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Directory to save the Midi files\n",
    "save_dir = 'piano/'\n",
    "\n",
    "# Url is plsit into two so we can go through the pages of the search results\n",
    "url0 = 'https://www.mutopiaproject.org/cgibin/make-table.cgi?startat='\n",
    "url1 = '&searchingfor=&Composer=&Instrument=Piano&Style=Jazz&collection=&id=&solo=1&recent=&timelength=1&timeunit=week&lilyversion=&preview='\n",
    "\n",
    "# Init values\n",
    "song_number = 0\n",
    "link_count = 10\n",
    "\n",
    "file_name = 0\n",
    "\n",
    "# main loop\n",
    "while link_count > 0:\n",
    "    #finds the correct page of search results\n",
    "    url = url0 + str(song_number) + url1\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html.read())\n",
    "    # Finds all the links on the page\n",
    "    links = soup.find_all('a')\n",
    "    link_count = 0\n",
    "\n",
    "    for link in links:\n",
    "        href = link['href']\n",
    "        # Find all links with a .mid in them\n",
    "        if href.find('.mid') >= 0:\n",
    "            link_count = link_count + 1\n",
    "            #Download that link\n",
    "            urlretrieve(href, 'piano/'+str(file_name)+'.mid' )\n",
    "            file_name += 1\n",
    "\n",
    "    #+10 since there are 10 results on each page\n",
    "    song_number += 10\n",
    "    # Small wait to be nice to the website\n",
    "    time.sleep(10.0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Next we have to extract the data from the Midi files and preprocess it\n",
    "\n",
    "import os\n",
    "from music21 import converter, pitch, interval, instrument, note, chord\n",
    "import numpy as np\n",
    "import tensorflow.keras.utils as np_utils\n",
    "\n",
    "save_dir = 'piano/'\n",
    "\n",
    "song_list = os.listdir(save_dir)\n",
    "\n",
    "original_scores = []\n",
    "\n",
    "# Adds the parsed songs to a list\n",
    "for song in song_list:\n",
    "    score = converter.parse(save_dir+song)\n",
    "    original_scores.append(score)\n",
    "\n",
    "# Remove polyphonic music (multiple instruments)\n",
    "# This function checks for monophonic music\n",
    "# If we don't do this, notes from multiple instruments will be combined into chords\n",
    "def monophonic(stream):\n",
    "    try:\n",
    "        length = len(instrument.partitionByInstrument(stream).parts)\n",
    "    except:\n",
    "        length = 0\n",
    "    return length == 1\n",
    "\n",
    "# Loops through songs, checks they are monophonic then chordifies and adds to list\n",
    "original_scores_chordified = []\n",
    "for song in original_scores:\n",
    "    if monophonic(song):\n",
    "        original_scores_chordified.append(song.chordify())\n",
    "\n",
    "original_scores = original_scores_chordified\n",
    "\n",
    "# Now we need to extract the notes, chords and durations from the songs\n",
    "original_chords = [[] for _ in original_scores] #empty list of lists\n",
    "original_durations = [[] for _ in original_scores]\n",
    "original_keys = []\n",
    "\n",
    "for i, song in enumerate(original_scores):\n",
    "    # Save the key of the song\n",
    "    original_keys.append(str(song.analyze('key')))\n",
    "    # Loop through the notes and chords\n",
    "    for element in song:\n",
    "        # if note\n",
    "        if isinstance(element, note.Note):\n",
    "            # add note\n",
    "            original_chords[i].append(element.pitch)\n",
    "            original_durations[i].append(element.duration.quarterLength)\n",
    "        # if chord\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            # add all notes making up chord\n",
    "            original_chords[i].append('.'.join(str(n) for n in element.pitches))\n",
    "            original_durations[i].append(element.duration.quarterLength)\n",
    "\n",
    "    print(str(i))\n",
    "\n",
    "# I am going to keep all the key signatures for now unlike tutorial\n",
    "\n",
    "# Identify unique notes and chords and create dictionaries to convert to ints\n",
    "unique_chords = np.unique([i for s in original_chords for i in s])\n",
    "chord_to_int = dict(zip(unique_chords, list(range(0, len(unique_chords)))))\n",
    "\n",
    "# Map durations to ints too\n",
    "unique_dur = np.unique([i for s in original_durations for i in s])\n",
    "dur_to_int = dict(zip(unique_dur, list(range(0, len(unique_dur)))))\n",
    "\n",
    "print(len(unique_chords))\n",
    "print(len(unique_dur))\n",
    "\n",
    "# We also need dictionaries to convert the other way\n",
    "int_to_chord = {i: c for c, i in chord_to_int.items()}\n",
    "int_to_dur = {i: c for c, i in dur_to_int.items()}\n",
    "\n",
    "# Lastly we can make our training sequences and target notes\n",
    "seq_len = 32\n",
    "\n",
    "train_chords = []\n",
    "train_dur = []\n",
    "\n",
    "target_chords = []\n",
    "target_dur = []\n",
    "\n",
    "# loop through the chords\n",
    "for s in range(len(original_chords)):\n",
    "    # create a list of ints from the chord list\n",
    "    chord_list = [chord_to_int[c] for c in original_chords[s]]\n",
    "    dur_list = [dur_to_int[d] for d in original_durations[s]]\n",
    "\n",
    "    # make sequences 32 in length and add to the training lists\n",
    "    for i in range(len(chord_list) - seq_len):\n",
    "        train_chords.append(chord_list[i:i+seq_len])\n",
    "        train_dur.append(dur_list[i:i+seq_len])\n",
    "\n",
    "        target_chords.append(chord_list[i+1])\n",
    "        target_dur.append(dur_list[i+1])\n",
    "\n",
    "# Reshape to fit LSTM\n",
    "input_chords = np.reshape(np.array(train_chords), (len(train_chords), seq_len,1))\n",
    "input_dur = np.reshape(np.array(train_dur), (len(train_dur), seq_len, 1))\n",
    "# Normalise these\n",
    "input_chords = input_chords / float(len(unique_chords))\n",
    "input_dur = input_dur / float(len(unique_dur))\n",
    "# Make target notes categorical\n",
    "target_chords = np_utils.to_categorical(target_chords)\n",
    "target_dur = np_utils.to_categorical(target_dur)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "3248\n",
      "16\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Set up our LSTM model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Change lists to np arrays and get dims\n",
    "train_chords = np.array(train_chords)\n",
    "n_samples = train_chords.shape[0]\n",
    "n_chords = train_chords.shape[1]\n",
    "\n",
    "train_dur = np.array(train_dur)\n",
    "n_dur = train_dur.shape[1]\n",
    "n_samples_dur = train_dur.shape[0]\n",
    "\n",
    "# Set input dim for NN\n",
    "input_dim = n_chords * seq_len\n",
    "embed_dim = 64\n",
    "\n",
    "# We want 2 inputs and outputs\n",
    "chord_input = tf.keras.layers.Input(shape = (None,))\n",
    "dur_input = tf.keras.layers.Input(shape = (None,))\n",
    "\n",
    "# Embed layers (lookup tables goes from sparse -> dense)\n",
    "chord_embedding = tf.keras.layers.Embedding(n_samples, embed_dim, input_length = seq_len)(chord_input)\n",
    "dur_embedding = tf.keras.layers.Embedding(n_samples_dur, embed_dim, input_length = seq_len)(dur_input)\n",
    "\n",
    "# Merge layer that concatenates 2 embed layers before going into LSTM layers\n",
    "merge_layer = tf.keras.layers.Concatenate(axis=1)([chord_embedding, dur_embedding])\n",
    "\n",
    "# LSTM layer\n",
    "lstm_layer = tf.keras.layers.LSTM(512, return_sequences=True)(merge_layer)\n",
    "\n",
    "# Dense layer\n",
    "dense_layer = tf.keras.layers.Dense(256)(lstm_layer)\n",
    "\n",
    "# Output Layers\n",
    "chord_output = tf.keras.layers.Dense(n_chords, activation = 'softmax')(dense_layer)\n",
    "dur_output = tf.keras.layers.Dense(n_dur, activation = 'softmax')(dense_layer)\n",
    "\n",
    "# Overall model\n",
    "lstm = tf.keras.Model(inputs = [chord_input, dur_input], outputs = [chord_output, dur_output])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Compile the model\n",
    "lstm.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "\n",
    "# train the model\n",
    "lstm.fit([train_chords, train_dur], [np.array(target_chords), np.array(target_dur)], epochs=500, batch_size=64)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 64]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at tmp/ipykernel_4231/3803088062.py:6) ]] [Op:__inference_train_function_26317]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4231/3803088062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_chords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dur\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_chords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/MLvenv/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MLvenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MLvenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MLvenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MLvenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Documents/MLvenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MLvenv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 64]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at tmp/ipykernel_4231/3803088062.py:6) ]] [Op:__inference_train_function_26317]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "lstm.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, None, 64)     862912      input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, None, 64)     862912      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, None, 64)     0           embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, None, 512)    1181696     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, None, 256)    131328      lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, None, 32)     8224        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, None, 32)     8224        dense_27[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,055,296\n",
      "Trainable params: 3,055,296\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('MLvenv': venv)"
  },
  "interpreter": {
   "hash": "3c5deedbfea70084e63f288ba49a2f9456761c977349528e54a40dbdea00cf01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}